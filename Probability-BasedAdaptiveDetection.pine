//@version=6
indicator('Probability-Based Adaptive Detection', 'PBAD', true, timeframe = '', timeframe_gaps = false)
//by gorx1


//  dependencies........................................................................................................
kde_kernel(kernel_name, distance, bandwidth) => //  raw kernels, ain't unit variance ones
    u = distance / bandwidth
    switch kernel_name
        'beta2'    => math.abs(u) <= 1 ? 0.75                             / bandwidth * (1 - u * u)                 : 0
        'uniform'  => math.abs(u) <= 1 ? 0.5                              / bandwidth                               : 0
        'normal'   =>                    1 / math.sqrt(2 * math.pi)       / bandwidth * math.exp(-0.5 * u * u)
        'laplace'  =>                    0.5                              / bandwidth * math.exp(-math.abs(u))
        'student5' =>                    8 / (3 * math.sqrt(5) * math.pi) / bandwidth * math.pow(1 + u * u / 5, -3)


kde(data, weights, kernel_name, bandwidth, nsteps, len) =>
    sum_w  = weights.sum()
    min_x  = data.min()
    max_x  = data.max()
    range_ = max_x - min_x
    n      = int(2 * nsteps + 1)
    step   = range_ / (n - 1)

    x      = array.new_float(n)
    y      = array.new_float(n)

    for k = 0 to n - 1
        xi  = min_x + step * k
        acc = 0.

        for j = 0 to len - 1
            acc += weights.get(j) * kde_kernel(kernel_name, xi - data.get(j), bandwidth)
            
        x.set(k, xi         )
        y.set(k, acc / sum_w)  

    //  normalizaion to ensure probs gonna sum up to 1
    norm_factor = y.sum() * step

    for i = 0 to n - 1
        y.set(i, y.get(i) / norm_factor)


    [x, y]  //  x = prices, y = probabilities


kde_mode(data, weights, len, kernel_name, bandwidth, nsteps) =>
    [values, probabilities] = kde(data, weights, kernel_name, bandwidth, nsteps, len)

    array.new<float>(len, values.get(probabilities.indexof(probabilities.max())))


multisort(array_base, array_second, reverse = false) =>
    len = array_base.size()

    sorted_indices      = array_base.sort_indices(reverse ? order.descending : order.ascending)

    sorted_array_base   = array.new_float(len)
    sorted_array_second = array.new_float(len)
    
    for i = 0 to len - 1
        idx = sorted_indices.get(i)
        
        sorted_array_base  .set(i, array_base  .get(idx))
        sorted_array_second.set(i, array_second.get(idx))
    

    [sorted_array_base, sorted_array_second]


coth(x) => (math.exp(2 * x) + 1) / (math.exp(2 * x) - 1)//  üêà‚Äç‚¨õüê±üêàüòº  Look ->    ‚òê ‚à£ ‚àü ‚äî    <- Your native num system
tanh(x) => (math.exp(2 * x) - 1) / (math.exp(2 * x) + 1)//             ^^ you just have to recall it ^^


probability_moments(data, weights, fit, len, kernel_name, bandwidth, nsteps) =>
    residuals = array.new_float(len, 0)

    for [i, v] in data
        residuals.set(i, data.get(i) - fit.get(i)) 


    max_x  = residuals.max()
    min_x  = residuals.min()
    range_ = max_x - min_x
    N      = int(2 * nsteps + 1)
    step   = range_ / (N - 1)

    [values, probabilities] = kde(residuals, weights, kernel_name, bandwidth, nsteps, len)

    [sorted_probabilities, sorted_values] = multisort(probabilities, values, true)  // true = descending


    // target_init  = tanh(0.5 * (0 - 1))
    // target_bias  = tanh(0.5 * (1 - 1))
    target_dev   = tanh(0.5 * (2 - 1))
    target_skew  = tanh(0.5 * (3 - 1))
    target_kurt  = tanh(0.5 * (4 - 1))
    target_hskew = tanh(0.5 * (5 - 1))
    target_hkurt = tanh(0.5 * (6 - 1))


    float bound_hk_l = na
    float bound_hs_l = na
    float bound_k_l  = na
    float bound_s_l  = na
    float bound_d_l  = na
    // float bound_b_l  = na
    // float bound_i_l  = na

    // float bound_i_u  = na
    // float bound_b_u  = na
    float bound_d_u  = na
    float bound_s_u  = na
    float bound_k_u  = na
    float bound_hs_u = na
    float bound_hk_u = na

    cumulative = 0.

    for i = 0 to sorted_probabilities.size() - 1
        prob  = sorted_probabilities.get(i)
        value = sorted_values       .get(i)

        cumulative += prob * step


        // if cumulative <= target_init
        //     bound_i_l := na(bound_i_l) ? value : math.min(bound_i_l, value)
        //     bound_i_u := na(bound_i_u) ? value : math.max(bound_i_u, value)

        // if cumulative <= target_bias
        //     bound_b_l := na(bound_b_l) ? value : math.min(bound_b_l, value)
        //     bound_b_u := na(bound_b_u) ? value : math.max(bound_b_u, value)

        if cumulative <= target_dev
            bound_d_l := na(bound_d_l) ? value : math.min(bound_d_l, value)
            bound_d_u := na(bound_d_u) ? value : math.max(bound_d_u, value)

        if cumulative <= target_skew
            bound_s_l := na(bound_s_l) ? value : math.min(bound_s_l, value)
            bound_s_u := na(bound_s_u) ? value : math.max(bound_s_u, value)

        if cumulative <= target_kurt
            bound_k_l := na(bound_k_l) ? value : math.min(bound_k_l, value)
            bound_k_u := na(bound_k_u) ? value : math.max(bound_k_u, value)

        if cumulative <= target_hskew
            bound_hs_l := na(bound_hs_l) ? value : math.min(bound_hs_l, value)
            bound_hs_u := na(bound_hs_u) ? value : math.max(bound_hs_u, value)

        if cumulative <= target_hkurt
            bound_hk_l := na(bound_hk_l) ? value : math.min(bound_hk_l, value)
            bound_hk_u := na(bound_hk_u) ? value : math.max(bound_hk_u, value)


    m0 = 1
    m1 = 0
    m2 = (bound_d_u  - bound_d_l ) / 2
    m3 = (bound_s_u  + bound_s_l ) / 2
    m4 = (bound_k_u  - bound_k_l ) / 2
    m5 = (bound_hs_u + bound_hs_l) / 2
    m6 = (bound_hk_u - bound_hk_l) / 2


    moments = array.new_float(7)

    moments.set(0, m0     )
    moments.set(1, m1     )
    moments.set(2, m2     )
    moments.set(3, m3 / m2)
    moments.set(4, m4 / m2)
    moments.set(5, m5 / m2)
    moments.set(6, m6 / m2)


    moments


type distro
    float low_lim
    float low_ext
    float low_dev
    float basis
    float upp_dev
    float upp_ext
    float upp_lim
    float dev
    float asym


pbad(data_y, weights, len, kernel_name, bandwidth, nsteps) =>
    fit     = kde_mode           (data_y, weights,      len, kernel_name, bandwidth, nsteps)
    moments = probability_moments(data_y, weights, fit, len, kernel_name, bandwidth, nsteps)
    center  = fit.get(0)

    init  = moments.get(0)
    bias  = moments.get(1)
    dev   = moments.get(2)
    skew  = moments.get(3)
    kurt  = moments.get(4)
    hskew = moments.get(5)
    hkurt = moments.get(6)

    
    out = distro.new()

    out.basis := center 

    out.low_dev := out.basis - (dev - bias)                      
    out.upp_dev := out.basis + (dev + bias)                      

    mid_value = (out.upp_dev - out.low_dev) / 2

    out.low_ext := out.low_dev - mid_value - (dev - bias) * ( kurt -  skew)
    out.upp_ext := out.upp_dev + mid_value + (dev + bias) * ( kurt +  skew)

    mid_frame = (out.upp_ext - out.low_ext) / 2

    out.low_lim := out.low_ext - mid_frame - (dev - bias) * (hkurt - hskew)
    out.upp_lim := out.upp_ext + mid_frame + (dev + bias) * (hkurt + hskew)

    mid_field = (out.upp_lim - out.low_lim) / 2


    out.dev := dev    

    out.asym := ((skew / kurt) - (hskew / hkurt)) * dev * 2
    

    out
//  dependencies........................................................................................................


//  data interval logic.................................................................................................
anchor  = input.string('Session', 'anchor',
 ['1', '5', '24h', 'Session', 'Year', 'Cumulative', 'Moving window', 'Custom session'], group = 'interval')

length  = input        (256        , 'moving window length' , group = 'interval')
session = input.session('0000-2345', 'custom session period', group = 'interval')
hybrid  = input        (false      , 'hybrid window'        , group = 'interval')

isNewPeriod = switch anchor
    '1'       => timeframe.change('1'   )
    '5'       => timeframe.change('5'   )
    '24h'     => timeframe.change('1440')
	'Session' => timeframe.change('D'   )
	'Year'    => timeframe.change('12M' )

if na(close[1])
	isNewPeriod := true

var barsInSession = 0
barsInSession    := isNewPeriod ? 1 : 1 + barsInSession

var barsInSessionCustom = 0
barsInSessionCustom    := na(time('', session)) ? 1 : 1 + barsInSessionCustom

len = if anchor == 'Cumulative'
    bar_index + 1
else  if anchor == 'Moving window'
    length
else  if anchor == 'Custom session'
    barsInSessionCustom
else
    barsInSession + (hybrid ? length : 0)

len := len > bar_index + 1 ? bar_index + 1 : len
//  data interval logic.................................................................................................


//  main................................................................................................................
src   = input(hlc3, 'Source'                                                      )
time_ = input(true, 'Sequence'             , inline = '1', group = 'Weighting by:')
force = input(true, 'Inferred volume delta', inline = '1', group = 'Weighting by:')

kernel_name = input.string('student5', 'kernel'                      , 
                           ['beta2', 'uniform', 'normal', 'laplace', 'student5']   , group = 'parameters')


data    = array.new_float(len)
weights = array.new_float(len)

for i = 0 to len - 1
    data   .set(i, src[i]                                                                                          )
    weights.set(i, (time_ ? (len - i) : 1) * (force ? 256 * math.abs(close[i] - open[i]) / syminfo.mintick + 1 : 1))


h_constant = switch kernel_name
    'beta2'    => 1.71877193 //  properly solved and computed with mpmath python module, 256 decimal precision
    'uniform'  => 1.35096004 //  properly solved and computed with mpmath python module, 256 decimal precision
    'normal'   => 0.77638836 //  properly solved and computed with mpmath python module, 256 decimal precision
    'laplace'  => 0.57434918 //  properly solved and computed with mpmath python module, 256 decimal precision
    'student5' => 0.61736376 //  properly solved and computed with mpmath python module, 256 decimal precision

nsteps    = len // equality in steps across fields
bandwidth = ta.range(src, len) / math.sqrt(12) * math.pow(len, -0.2) * h_constant

//  workaround for easy manual backtesting due to high algocomplexity of the thing
calc_period = input(2048, 'calculate for N bars', 'calculation period'              , group = 'parameters')
calc_start  = input(0   , 'starting at bar N'   , "put 0 to calculate 'last' N bars", group = 'parameters')


distro distro_data = distro.new()

if calc_start < 1
    if last_bar_index - bar_index < calc_period
        distro_data := pbad(data, weights, len, kernel_name, bandwidth, nsteps)
else
    if (bar_index < calc_period + calc_start) and (bar_index > calc_start)
        distro_data := pbad(data, weights, len, kernel_name, bandwidth, nsteps)
//  main................................................................................................................


//  visuals.............................................................................................................
viz_off = input(1, 'plotting offset', group = 'style') //always 1 for objective analysis, latest datapoint self inclusion is should Not be done

plot(distro_data.low_lim, 'lower limit'    , color.red   , 1, plot.style_stepline, offset = viz_off)
plot(distro_data.low_ext, 'lower extension', color.red   , 1, plot.style_stepline, offset = viz_off)
plot(distro_data.low_dev, 'lower deviation', color.purple, 1, plot.style_stepline, offset = viz_off)
plot(distro_data.basis  , 'basis'          , color.purple, 1, plot.style_stepline, offset = viz_off)
plot(distro_data.upp_dev, 'upper deviation', color.purple, 1, plot.style_stepline, offset = viz_off)
plot(distro_data.upp_ext, 'upper extension', color.blue  , 1, plot.style_stepline, offset = viz_off)
plot(distro_data.upp_lim, 'upper limit'    , color.blue  , 1, plot.style_stepline, offset = viz_off)
//  visuals.............................................................................................................


//  ‚àû
